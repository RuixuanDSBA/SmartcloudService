{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 5,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "code",
			"source": "import sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom pyspark.sql import SQLContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import pandas_udf, PandasUDFType,udf\nfrom pyspark.sql.types import IntegerType, StringType\nfrom pyspark.sql.functions import *\n\nfrom datetime import datetime, timezone, timedelta\nimport pytz\n\nglueContext = GlueContext(SparkContext.getOrCreate())",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": [
				{
					"name": "stdout",
					"text": "Welcome to the Glue Interactive Sessions Kernel\nFor more information on available magic commands, please type %help in any new cell.\n\nPlease view our Getting Started page to access the most up-to-date information on the Interactive Sessions kernel: https://docs.aws.amazon.com/glue/latest/dg/interactive-sessions.html\nInstalled kernel version: 0.35 \nAuthenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::087763889191:role/service-role/AWSGlueServiceRole-imba-nining\nTrying to create a Glue session for the kernel.\nWorker Type: G.1X\nNumber of Workers: 5\nSession ID: ca4071c2-730a-47ce-9bbb-7a5f8ba3d528\nApplying the following default arguments:\n--glue_kernel_version 0.35\n--enable-glue-datacatalog true\nWaiting for session ca4071c2-730a-47ce-9bbb-7a5f8ba3d528 to get into ready status...\nSession ca4071c2-730a-47ce-9bbb-7a5f8ba3d528 has been created\n\n\n",
					"output_type": "stream"
				}
			],
			"id": "2cde1bb9"
		},
		{
			"cell_type": "code",
			"source": "#crawler the data from data source, then define raw data zone as database for the data.\ndata_order = glueContext.create_dynamic_frame.from_catalog(database=\"raw data zone\", table_name=\"orders\")\nprint(\"Count: \" + str(data_order.count()))\nprint(type(data_order))\ndata_order.printSchema()\n\nprint(type(data_order))\n\n# data_product = glueContext.create_dynamic_frame.from_catalog(database=\"raw data zone\", table_name=\"products\")\n# print(\"Count: \" + str(data_product.count()))\n# data_product.printSchema()\n\ndata_order_prior = glueContext.create_dynamic_frame.from_catalog(database=\"raw data zone\", table_name=\"order_products\")\nprint(\"Count: \" + str(data_order_prior.count()))\ndata_order_prior.printSchema()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [
				{
					"name": "stdout",
					"text": "Count: 39\n<class 'awsglue.dynamicframe.DynamicFrame'>\nroot\n|-- order_id: long\n|-- user_id: long\n|-- eval_set: string\n|-- order_number: long\n|-- order_dow: long\n|-- order_hour_of_day: long\n|-- days_since_prior_order: long\n\n<class 'awsglue.dynamicframe.DynamicFrame'>\nCount: 384\nroot\n|-- order_id: long\n|-- product_id: long\n|-- add_to_cart_order: long\n|-- reordered: long\n|-- partition_0: string\n",
					"output_type": "stream"
				}
			],
			"id": "3bcc8016"
		},
		{
			"cell_type": "code",
			"source": "#departments is just one table in database, so you can load other tables like aisles, orders, etc. one by one\ndata_order = data_order.toDF()\ndata_order.show(5)\n\n# data_product = data_product.toDF()\n# data_product.show(5)\n\ndata_order_prior =data_order_prior.toDF()\ndata_order_prior.show(5)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 2,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+-------+--------+------------+---------+-----------------+----------------------+\n|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|\n+--------+-------+--------+------------+---------+-----------------+----------------------+\n| 2539329|      1|   prior|           1|        2|                8|                  null|\n| 2398795|      1|   prior|           2|        3|                7|                    15|\n|  473747|      1|   prior|           3|        3|               12|                    21|\n| 2254736|      1|   prior|           4|        4|                7|                    29|\n|  431534|      1|   prior|           5|        4|               15|                    28|\n+--------+-------+--------+------------+---------+-----------------+----------------------+\nonly showing top 5 rows\n\n+--------+----------+-----------------+---------+--------------------+\n|order_id|product_id|add_to_cart_order|reordered|         partition_0|\n+--------+----------+-----------------+---------+--------------------+\n| 1187899|       196|                1|        1|order_products_train|\n| 1187899|     25133|                2|        1|order_products_train|\n| 1187899|     38928|                3|        1|order_products_train|\n| 1187899|     26405|                4|        1|order_products_train|\n| 1187899|     39657|                5|        1|order_products_train|\n+--------+----------+-----------------+---------+--------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			],
			"id": "02764a0d"
		},
		{
			"cell_type": "code",
			"source": "data_order.createOrReplaceTempView(\"orders\")\ndata_order_prior.createOrReplaceTempView(\"order_products\")\nprint(type(data_order))\ndf_SQL = spark.sql(\"SELECT a.*,b.product_id, b.add_to_cart_order, b.reordered FROM orders as a JOIN order_products as b ON a.order_id = b.order_id WHERE a.eval_set = 'prior'\")\ndf_SQL.show(5)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "<class 'pyspark.sql.dataframe.DataFrame'>\n+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+\n|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|product_id|add_to_cart_order|reordered|\n+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+\n|  431534|      1|   prior|           5|        4|               15|                    28|       196|                1|        1|\n|  431534|      1|   prior|           5|        4|               15|                    28|     12427|                2|        1|\n|  431534|      1|   prior|           5|        4|               15|                    28|     10258|                3|        1|\n|  431534|      1|   prior|           5|        4|               15|                    28|     25133|                4|        1|\n|  431534|      1|   prior|           5|        4|               15|                    28|     10326|                5|        0|\n+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			],
			"id": "4b5ca93a-a211-48b3-a405-0730bca918b9"
		},
		{
			"cell_type": "code",
			"source": "df_SQL.createOrReplaceTempView(\"order_products_prior\")\nuser_features_1 = spark.sql(\"SELECT user_id, \\\nMax(order_number) AS user_orders, \\\nSum(days_since_prior_order) AS user_period, \\\nAvg(days_since_prior_order) AS user_mean_days_since_prior \\\nFROM orders \\\nGROUP BY user_id\")\n\nuser_features_1.show(5)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 4,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+-----------+-----------+--------------------------+\n|user_id|user_orders|user_period|user_mean_days_since_prior|\n+-------+-----------+-----------+--------------------------+\n|      2|         15|        228|        16.285714285714285|\n|      3|         13|        144|                      12.0|\n|      1|         11|        190|                      19.0|\n+-------+-----------+-----------+--------------------------+\n",
					"output_type": "stream"
				}
			],
			"id": "cc868368-e235-489b-9d20-a7bec809aaf1"
		},
		{
			"cell_type": "code",
			"source": "user_features_2 = spark.sql(\"SELECT user_id, \\\nCount(*) AS user_total_products, \\\nCount(DISTINCT product_id) AS user_distinct_products, \\\nSum(CASE WHEN reordered = 1 THEN 1 ELSE 0 END) / Cast(Sum(CASE WHEN order_number > 1 THEN 1 ELSE 0 END) AS DOUBLE) AS user_reorder_ratio \\\nFROM order_products_prior  \\\nGROUP BY user_id\")\nuser_features_2.show(5)\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": 5,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+-------------------+----------------------+------------------+\n|user_id|user_total_products|user_distinct_products|user_reorder_ratio|\n+-------+-------------------+----------------------+------------------+\n|      2|                195|                   102| 0.510989010989011|\n|      3|                 88|                    33|0.7051282051282052|\n|      1|                 59|                    18|0.7592592592592593|\n+-------+-------------------+----------------------+------------------+\n",
					"output_type": "stream"
				}
			],
			"id": "cad3f054-3c63-4a74-a286-0a07a92f6dbb"
		},
		{
			"cell_type": "code",
			"source": "up_features = spark.sql(\"SELECT user_id, \\\nproduct_id, \\\nCount(*) AS up_orders, \\\nMin(order_number) AS up_first_order, \\\nMax(order_number) AS up_last_order, \\\nAvg(add_to_cart_order) AS up_average_cart_position \\\nFROM order_products_prior \\\nGROUP BY user_id, product_id\") \nup_features.show(5)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 6,
			"outputs": [
				{
					"name": "stdout",
					"text": "+-------+----------+---------+--------------+-------------+------------------------+\n|user_id|product_id|up_orders|up_first_order|up_last_order|up_average_cart_position|\n+-------+----------+---------+--------------+-------------+------------------------+\n|      2|     48110|        2|             1|            8|                     5.0|\n|      3|     24810|        3|             1|           12|                     7.0|\n|      2|     39928|        1|            14|           14|                    13.0|\n|      3|     17668|        5|             1|           11|                     3.6|\n|      2|     10305|        1|            12|           12|                    10.0|\n+-------+----------+---------+--------------+-------------+------------------------+\nonly showing top 5 rows\n",
					"output_type": "stream"
				}
			],
			"id": "3fd7f3d9-4fcb-4d14-a114-ebb0adf85c48"
		},
		{
			"cell_type": "code",
			"source": "prd_features_pri = spark.sql(\"SELECT *, Rank() OVER(partition BY user_id, product_id \\\nORDER BY order_number) AS product_seq_time \\\nFROM order_products_prior\")\nprd_features_pri.show(5)\n\nprd_features_pri.createOrReplaceTempView(\"prd_features_pri1\")\n\nprd_features = spark.sql(\"SELECT product_id, \\\nCount(*) AS prod_orders, \\\nSum(reordered) AS prod_reorders, \\\nSum(CASE WHEN product_seq_time = 1 THEN 1 ELSE 0 END) AS prod_first_orders, \\\nSum(CASE WHEN product_seq_time = 2 THEN 1 ELSE 0 END) AS prod_second_orders \\\nFROM prd_features_pri1 \\\nGROUP BY product_id\") \n\nprd_features.show(10)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 7,
			"outputs": [
				{
					"name": "stdout",
					"text": "+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+----------------+\n|order_id|user_id|eval_set|order_number|order_dow|order_hour_of_day|days_since_prior_order|product_id|add_to_cart_order|reordered|product_seq_time|\n+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+----------------+\n| 2168274|      2|   prior|           1|        2|               11|                  null|     48110|                5|        0|               1|\n|  788338|      2|   prior|           8|        1|               15|                    27|     48110|                5|        1|               2|\n| 1374495|      3|   prior|           1|        1|               14|                  null|     24810|                9|        0|               1|\n| 1972919|      3|   prior|           6|        0|               16|                     7|     24810|                6|        1|               2|\n| 1402502|      3|   prior|          12|        1|               15|                    15|     24810|                6|        1|               3|\n+--------+-------+--------+------------+---------+-----------------+----------------------+----------+-----------------+---------+----------------+\nonly showing top 5 rows\n\n+----------+-----------+-------------+-----------------+------------------+\n|product_id|prod_orders|prod_reorders|prod_first_orders|prod_second_orders|\n+----------+-----------+-------------+-----------------+------------------+\n|     16797|          4|            2|                2|                 1|\n|     16965|          2|            1|                1|                 1|\n|     19057|          1|            0|                1|                 0|\n|     47766|         13|           11|                2|                 2|\n|     25133|          8|            7|                1|                 1|\n|     30450|          1|            0|                1|                 0|\n|     22124|          4|            3|                1|                 1|\n|     22035|          3|            2|                1|                 1|\n|     38596|          1|            0|                1|                 0|\n|      5212|          1|            0|                1|                 0|\n+----------+-----------+-------------+-----------------+------------------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			],
			"id": "ed3b3763-4341-4330-b0b7-b11606ed7a00"
		},
		{
			"cell_type": "code",
			"source": "\ntoday = datetime.utcnow().replace(tzinfo=timezone.utc) \nSydney = timezone(timedelta(hours=11))\ndate_time = today.astimezone(Sydney).strftime(\"%Y-%m-%d %H:%M:%S\")\nprint(date_time)\n\n\nuser_features_1 =user_features_1.repartition(1)\nuser_features_1.write.parquet(f's3://project-imba/data-lake/feature_extract/user_features_1/{date_time}/')\n                              \nuser_features_2 =user_features_2.repartition(1)\nuser_features_2.write.parquet(f's3://project-imba/data-lake/feature_extract/user_features_2/{date_time}/')\n                              \nup_features =up_features.repartition(1)\nup_features.write.parquet(f's3://project-imba/data-lake/feature_extract/up_features/{date_time}/')\n                          \nprd_features =prd_features.repartition(1)\nprd_features.write.parquet(f's3://project-imba/data-lake/feature_extract/prd_features/{date_time}/')\n                           ",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "2023-01-01 00:17:47\n",
					"output_type": "stream"
				}
			],
			"id": "668c5b9c-3477-487d-8d90-83b421ce881d"
		},
		{
			"cell_type": "code",
			"source": "  # creating dataframes from existing athena catelog\nup_features = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [f's3://project-imba/data-lake/feature_extract/up_features/{date_time}/']})\nprd_features = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [f's3://project-imba/data-lake/feature_extract/prd_features/{date_time}/']})\nuser_features_1 = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [f's3://project-imba/data-lake/feature_extract/user_features_1/{date_time}/']})\nuser_features_2 = glueContext.create_dynamic_frame_from_options(connection_type = \"parquet\", connection_options = {\"paths\": [f's3://project-imba/data-lake/feature_extract/user_features_2/{date_time}/']})\n\n# join user features together\nusers = Join.apply(user_features_1.rename_field('user_id','user_id1'), user_features_2, 'user_id1', 'user_id').drop_fields(['user_id1'])\n\n# join everything together\ndf = Join.apply(Join.apply(up_features, \n                  users.rename_field('user_id','user_id1'), \n                  'user_id','user_id1').drop_fields(['user_id1']),\n      prd_features.rename_field('product_id','product_id1'), \n      'product_id','product_id1').drop_fields(['product_id1'])\n\n# convert glue dynamic dataframe to spark dataframe\ndf_spark = df.toDF()\ndf_spark.repartition(1).write.mode('overwrite').format('csv').save(f's3://project-imba/data-lake/curated_data/output/{date_time}/', header = 'true')\ndf_spark.show(10)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+---------+--------------------------+-----------+----------------------+------------------+-------------+------------------+-------------------+------------------------+--------------+-----------+-------------+-----------+-----------------+-------+\n|product_id|up_orders|user_mean_days_since_prior|user_period|user_distinct_products|prod_second_orders|prod_reorders|user_reorder_ratio|user_total_products|up_average_cart_position|up_first_order|user_orders|up_last_order|prod_orders|prod_first_orders|user_id|\n+----------+---------+--------------------------+-----------+----------------------+------------------+-------------+------------------+-------------------+------------------------+--------------+-----------+-------------+-----------+-----------------+-------+\n|     12845|        1|                      12.0|        144|                    33|                 0|            0|0.7051282051282052|                 88|                     2.0|             4|         13|            4|          1|                1|      3|\n|     16797|        3|                      12.0|        144|                    33|                 1|            2|0.7051282051282052|                 88|                     4.0|             1|         13|            9|          4|                2|      3|\n|     16797|        1|        16.285714285714285|        228|                   102|                 1|            2| 0.510989010989011|                195|                     1.0|             2|         15|            2|          4|                2|      2|\n|     39928|        1|        16.285714285714285|        228|                   102|                 0|            0| 0.510989010989011|                195|                    13.0|            14|         15|           14|          1|                1|      2|\n|     33276|        2|        16.285714285714285|        228|                   102|                 1|            1| 0.510989010989011|                195|                    15.5|             4|         15|            6|          2|                1|      2|\n|        23|        1|        16.285714285714285|        228|                   102|                 0|            0| 0.510989010989011|                195|                    12.0|             8|         15|            8|          1|                1|      2|\n|     22035|        3|                      12.0|        144|                    33|                 1|            2|0.7051282051282052|                 88|      3.6666666666666665|             5|         13|            8|          3|                1|      3|\n|      3151|        1|        16.285714285714285|        228|                   102|                 0|            0| 0.510989010989011|                195|                     7.0|            12|         15|           12|          1|                1|      2|\n|     30450|        1|                      19.0|        190|                    18|                 0|            0|0.7592592592592593|                 59|                     5.0|             3|         11|            3|          1|                1|      1|\n|        79|        1|        16.285714285714285|        228|                   102|                 0|            0| 0.510989010989011|                195|                     3.0|            13|         15|           13|          1|                1|      2|\n+----------+---------+--------------------------+-----------+----------------------+------------------+-------------+------------------+-------------------+------------------------+--------------+-----------+-------------+-----------+-----------------+-------+\nonly showing top 10 rows\n",
					"output_type": "stream"
				}
			],
			"id": "b5dbf164-d80c-4272-8ce8-14cee03830bb"
		},
		{
			"cell_type": "code",
			"source": "# #data clean -- in this part, only one way, deduplication, is designed to demonstrate the clean process, you can add other methods to clean data\n# loc = locals()      #get string name\n# def get_variable_name(variable):\n#     for k,v in loc.items():\n#         if loc[k] is variable:\n#             return k\n\n\n# # def getString_name(df_name):\n# #      return list(dict(df_name = df_name).keys())[0]#,type(list(dict(df_name = df_name).values())[0])\n\n# def deduplicate_df(df_name):\n#     if df_name.count() != df_name.distinct().count():\n#         print( str(get_variable_name(df_name)) + ' have duplicated row:',df_name.count()- df_name.distinct().count())\n#         df_name = df_name.dropDuplicates()\n#         print('duplicated data has been cleared')\n#     else:\n#         print( str(get_variable_name(df_name)) + ' hasn\\'t duplication, the totle distinct row',df_name.count())\n#     return df_name\n\n# df_orders_clean = deduplicate_df(df_orders)\n# df_orders_clean.show(5)\n# df_products_clean = deduplicate_df(df_products)\n# df_order_products_clean = deduplicate_df(df_order_products)",
			"metadata": {
				"trusted": true
			},
			"execution_count": 1,
			"outputs": [],
			"id": "38e1b9f8"
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"id": "4b7afbd8-44b5-4f36-af4a-f678ab59d529"
		},
		{
			"cell_type": "code",
			"source": "# # put cleaned departments table into my datalake \n# df_products_clean =df_products_clean.repartition(1)\n# df_products_clean.write.parquet('s3://project-imba/data-lake/raw-data/products_clean)",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": [],
			"id": "e0fc2068"
		},
		{
			"cell_type": "code",
			"source": "# wide_table_for_ML=(df_orders_clean.select(\"order_id\",\"user_id\",\"order_number\")\\\n# .join(df_order_products,df_orders_clean.order_id==df_order_products.order_id,\"left\")\\\n# .drop(df_orders_clean.order_id)\\\n# .join(df_products,df_products.product_id == df_order_products.product_id,\"left\")\\\n# .drop(df_products.product_id)\\\n# .orderBy(\"user_id\",df_orders_clean.order_number,\"add_to_cart_order\")\\\n# .drop(\"reordered\",\"product_name\"))\\\n# .select(\"user_id\",\"order_id\",\"order_number\",\"department_id\",\"aisle_id\",\"product_id\",\"add_to_cart_order\",\"partition_0\")\\\n\n",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": [],
			"id": "c3813b91"
		},
		{
			"cell_type": "code",
			"source": "# wide_table_for_ML.show(503)",
			"metadata": {
				"trusted": true
			},
			"execution_count": null,
			"outputs": [],
			"id": "dab0df05-46dc-47b6-b197-581fefaf178a"
		},
		{
			"cell_type": "code",
			"source": "",
			"metadata": {},
			"execution_count": null,
			"outputs": [],
			"id": "5df9dad7-43c5-4382-882f-948a2b128a96"
		}
	]
}