{"cells":[{"cell_type":"code","source":["import dlt\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.types import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c1339550-66c9-480c-9915-75d5c4d6e355","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import datetime\nmonth = datetime.datetime.now().month"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa2cdf52-537e-4b60-851e-ef119e4425b3","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["@dlt.table\ndef df_orders():\n    df = (spark.readStream.format(\"cloudFiles\")\n        .option(\"cloudFiles.format\", \"csv\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"header\", \"true\")\n        .option(\"sep\", \",\")\n        .load(\"s3://yadi-pipeline/month-{}/orders\".format(month))\n    )\n    return df.withColumn(\"order_id\", col(\"order_id\").cast(IntegerType())).withColumn(\"user_id\", col(\"user_id\").cast(IntegerType())).withColumn(\"order_number\", col(\"order_number\").cast(IntegerType())).withColumn(\"order_dow\", col(\"order_dow\").cast(IntegerType())).withColumn(\"order_hour_of_day\", col(\"order_hour_of_day\").cast(IntegerType())).withColumn(\"days_since_prior_order\", col(\"days_since_prior_order\").cast(DoubleType()))\n\ndlt.create_target_table(\"silver_order\")\n\ndlt.apply_changes(\n  target = \"silver_order\",\n  source = \"df_orders\",\n  keys = [\"order_id\"],\n  sequence_by = col(\"order_id\")\n)\n\n@dlt.table\ndef df_products():\n    df = (spark.readStream.format(\"cloudFiles\")\n        .option(\"cloudFiles.format\", \"csv\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"header\", \"true\")\n        .option(\"sep\", \",\")\n        .load(\"s3://yadi-pipeline/month-{}/products\".format(month)))\n    return df.withColumn(\"product_id\", col(\"product_id\").cast(IntegerType())).withColumn(\"aisle_id\", col(\"aisle_id\").cast(IntegerType())).withColumn(\"department_id\", col(\"department_id\").cast(IntegerType()))\n\ndlt.create_target_table(\"silver_products\")\n\ndlt.apply_changes(\n  target = \"silver_products\",\n  source = \"df_products\",\n  keys = [\"product_id\"],\n  sequence_by = col(\"product_id\")\n)\n\n@dlt.table\ndef df_departments():\n    df = (spark\n          .readStream\n          .format(\"cloudFiles\")\n          .option(\"cloudFiles.format\", \"csv\")\n          .option(\"inferSchema\", \"true\")\n          .option(\"header\", \"true\")\n          .option(\"sep\", \",\")\n          .load(\"s3://yadi-pipeline/month-{}/departments\".format(month)))\n    return df.withColumn(\"department_id\", col(\"department_id\").cast(IntegerType()))\n\ndlt.create_target_table(\"silver_departments\")\n\ndlt.apply_changes(\n  target = \"silver_departments\",\n  source = \"df_departments\",\n  keys = [\"department_id\"],\n  sequence_by = col(\"department_id\")\n)\n\n@dlt.table\ndef df_aisles():\n    df = (spark.readStream.format(\"cloudFiles\")\n        .option(\"cloudFiles.format\", \"csv\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"header\", \"true\")\n        .option(\"sep\", \",\")\n        .load(\"s3://yadi-pipeline/month-{}/aisles\".format(month)))\n    return df.withColumn(\"aisle_id\", col(\"aisle_id\").cast(IntegerType()))\n\ndlt.create_target_table(\"silver_aisles\")\n\ndlt.apply_changes(\n  target = \"silver_aisles\",\n  source = \"df_aisles\",\n  keys = [\"aisle_id\"],\n  sequence_by = col(\"aisle_id\")\n)\n\n@dlt.table\ndef df_prior():\n    df = (spark.readStream.format(\"cloudFiles\")\n        .option(\"cloudFiles.format\", \"csv\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"header\", \"true\")\n        .option(\"sep\", \",\")\n        .load(\"s3://yadi-pipeline/month-{}/order_products__prior\".format(month))\n    )\n    return df.withColumn(\"order_id\", col(\"order_id\").cast(IntegerType())).withColumn(\"product_id\", col(\"product_id\").cast(IntegerType())).withColumn(\"add_to_cart_order\", col(\"add_to_cart_order\").cast(IntegerType())).withColumn(\"reordered\", col(\"reordered\").cast(IntegerType()))\n\ndlt.create_target_table(\"silver_prior\")\n\ndlt.apply_changes(\n  target = \"silver_prior\",\n  source = \"df_prior\",\n  keys = [\"order_id\", \"product_id\"],\n  sequence_by = col(\"order_id\")\n)\n\n@dlt.table\ndef df_train():\n    df = (spark.readStream.format(\"cloudFiles\")\n        .option(\"cloudFiles.format\", \"csv\")\n        .option(\"inferSchema\", \"true\")\n        .option(\"header\", \"true\")\n        .option(\"sep\", \",\")\n        .load(\"s3://yadi-pipeline/month-{}/order_products__train\".format(month))\n    )\n    return df.withColumn(\"order_id\", col(\"order_id\").cast(IntegerType())).withColumn(\"product_id\", col(\"product_id\").cast(IntegerType())).withColumn(\"add_to_cart_order\", col(\"add_to_cart_order\").cast(IntegerType())).withColumn(\"reordered\", col(\"reordered\").cast(IntegerType()))\n\ndlt.create_target_table(\"silver_train\")\n\ndlt.apply_changes(\n  target = \"silver_train\",\n  source = \"df_train\",\n  keys = [\"order_id\", \"product_id\"],\n  sequence_by = col(\"order_id\")\n)\n\n@dlt.table\ndef df_pad():\n    return (spark.sql(\"select p.product_id, p.product_name, p.aisle_id, a.aisle, p.department_id, d.department from LIVE.silver_products p, LIVE.silver_aisles a, LIVE.silver_departments d \" + \"where p.aisle_id == a.aisle_id and p.department_id == d.department_id \" + \"order by p.product_id\").withColumnRenamed(\"aisle\", \"aisle_name\").withColumnRenamed(\"department\", \"department_name\"))\n\n# dlt.create_streaming_live_table(\"silver_pad\")\n\n# dlt.apply_changes(\n#   target = \"silver_pad\",\n#   source = \"df_pad\",\n#   key = [\"product_id\"],\n#   sequence_by = col(\"ModifiedDate\"),\n#   apply_as_deletes = expr(\"operation = 'DELETE'\"),\n#   except_column_list = [\"operation\", \"ModifiedDate\"],\n#   stored_as_scd_type = \"2\"  \n# )\n\n@dlt.table\ndef df_op():\n    return (spark.sql(\"SELECT a.order_id, a.user_id, a.eval_set, a.order_number, a.order_dow, a.order_hour_of_day, a.days_since_prior_order, b.product_id, b.add_to_cart_order, b.reordered FROM LIVE.silver_order a JOIN LIVE.silver_prior b ON a.order_id = b.order_id WHERE a.eval_set = 'prior'\"))\n\n# dlt.create_streaming_live_table(\"silver_op\")\n\n# dlt.apply_changes(\n#     target = \"silver_op\",\n#     source = \"df_op\",\n#     key = [\"order_id\"],\n#     sequence_by = col(\"ModifiedDate\"),\n#     apply_as_deletes = expr(\"operation = 'DELETE'\"),\n#     except_column_list = [\"operation\", \"ModifiedDate\"],\n#     stored_as_scd_type = \"2\"  \n# )\n\n@dlt.table\ndef df_opp():\n    return (spark.sql(\"select p.order_id, o.user_id, p.product_id, a.product_name, a.aisle_id, a.aisle_name, a.department_id, a.department_name, p.add_to_cart_order, p.reordered from LIVE.silver_prior p, LIVE.silver_order o, LIVE.df_pad a \" + \"where p.order_id == o.order_id and p.product_id == a.product_id \" + \"order by p.order_id\"))\n\n# dlt.create_streaming_live_table(\"silver_opp\")\n\n# dlt.apply_changes(\n#     target = \"silver_opp\",\n#     source = \"df_opp\",\n#     key = [\"order_id\"],\n#     sequence_by = col(\"ModifiedDate\"),\n#     apply_as_deletes = expr(\"operation = 'DELETE'\"),\n#     except_column_list = [\"operation\", \"ModifiedDate\"],\n#     stored_as_scd_type = \"2\"  \n# )\n\n@dlt.table\ndef df_otp():\n    return (spark.sql(\"select t.order_id, o.user_id, t.product_id, a.product_name, a.aisle_id, a.aisle_name, a.department_id, a.department_name, t.add_to_cart_order, t.reordered from LIVE.silver_train t, LIVE.silver_order o, LIVE.df_pad a \" + \"where t.order_id == o.order_id and t.product_id == a.product_id \" + \"order by t.order_id\"))\n\n# dlt.create_streaming_live_table(\"silver_otp\")\n\n# dlt.apply_changes(\n#     target = \"silver_otp\",\n#     source = \"df_otp\",\n#     key = [\"order_id\"],\n#     sequence_by = col(\"ModifiedDate\"),\n#     apply_as_deletes = expr(\"operation = 'DELETE'\"),\n#     except_column_list = [\"operation\", \"ModifiedDate\"],\n#     stored_as_scd_type = \"2\"  \n# )\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6ebc0538-925e-47e2-8998-553ffaea7216","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pipeline-1","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":2126738811613291}},"nbformat":4,"nbformat_minor":0}
